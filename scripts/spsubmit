#!/usr/bin/env python

from subprocess import call
from importlib.machinery import SourceFileLoader
import os, sys

if __name__ == '__main__':
	# parse config.ini
	cwd = os.path.dirname(os.path.realpath(__file__))
	sprun = SourceFileLoader('get_config', cwd + '/sprun').load_module()
	get_config = getattr(sprun, 'get_config')
	config, workdir, add_path = get_config()

	# directory
	slurm = config['slurm']
	path = config['path']
	outdir = workdir + '/' + path['output']

	# ensure output directory exists
	if not os.path.exists(outdir):
		os.makedirs(outdir)

	if not os.path.exists(outdir + '/tmp'):
		os.makedirs(outdir + '/tmp')

	# slurm commands
	cmd = '#!/bin/bash\n'
	cmd += '#SBATCH --job-name=%s\n' % slurm['name']
	cmd += '#SBATCH --output=%s\n' % (outdir+'/'+'output.log')
	cmd += '#SBATCH --ntasks-per-node=%s\n' % slurm['tasks_per_node']
	cmd += '#SBATCH --nodes=%s\n' % slurm['nodes']
	cmd += '#SBATCH --time=%s\n' % slurm['time']
	cmd += '#SBATCH --gres=gpu:4\n'

	# custom command
	if 'command' in slurm:
		cmd += slurm['command'] + '\n'

	# load modules and run
	if add_path == 'yes':
		cmd += 'export PYTHONPATH=$PYTHONPATH:' + os.getcwd() + '\n'
	
	cmd += 'module load %s \n' % slurm['modules']
	cmd += 'srun python ' + cwd + '/sprun'

	# add arguments to submission script
	for i in range(1, len(sys.argv)):
		cmd += ' ' + sys.argv[i]

	cmd += '\n'

	# write to bash file
	slurm_file = outdir + '/job.bash'
	with open(slurm_file, 'w') as f:
		f.write(cmd)

	# submit bash file
	call('sbatch ' + slurm_file, shell=True)
